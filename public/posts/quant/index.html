<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>LLM Quantization | Zhiyang Shen&#39;s Blog</title>
<meta name="keywords" content="llm, code, system, quant">
<meta name="description" content="8bit-Quantization Implementation for LLama-2-7b Model">
<meta name="author" content="Zhiyang Shen">
<link rel="canonical" href="http://localhost:1313/posts/quant/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.9514d8875d000a50e6844112d7bdaaa71869d5b712f00bfe452405bd2e6514fd.css" integrity="sha256-lRTYh10AClDmhEES172qpxhp1bcS8Av&#43;RSQFvS5lFP0=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/quant/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>



</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Zhiyang Shen&#39;s Blog (Alt + H)">Zhiyang Shen&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://github.com/shenzhiy21" title="Github">
                    <span>Github</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      LLM Quantization
    </h1>
    <div class="post-meta"><span title='2025-02-23 13:00:00 +0800 CST'>February 23, 2025</span>&nbsp;·&nbsp;18 min&nbsp;·&nbsp;Zhiyang Shen

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#quantization-overview" aria-label="Quantization Overview">Quantization Overview</a></li>
                <li>
                    <a href="#naive-quantization" aria-label="Naive Quantization">Naive Quantization</a></li>
                <li>
                    <a href="#blockwise-quantization" aria-label="Blockwise Quantization">Blockwise Quantization</a></li>
                <li>
                    <a href="#biased-blockwise-quantization" aria-label="Biased Blockwise Quantization">Biased Blockwise Quantization</a></li>
                <li>
                    <a href="#another-hardware-efficient-approach" aria-label="Another Hardware Efficient Approach">Another Hardware Efficient Approach</a></li>
                <li>
                    <a href="#experiments" aria-label="Experiments">Experiments</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>之前实习的时候做了一些 LLM quantization 的尝试，然而当时连最简单的 8bit quantization 都没做到，深感挫折。最后虽然用了 <a href="https://arxiv.org/abs/2210.17323">GPTQ</a> 在微软的 <a href="https://github.com/microsoft/antares/">AutoRT</a> 框架下实现了 4bit quantization, 但是还是直接用的别人做好的 quant 后的权重。最近忽然意识到当时的代码有一个严重的 bug, 导致怎么调都调不出来。所以最近重新尝试，在这里记录一下一些实验现象以及小思考。</p>
<h2 id="quantization-overview">Quantization Overview<a hidden class="anchor" aria-hidden="true" href="#quantization-overview">#</a></h2>
<p>首先，为什么要研究大模型的量化？</p>
<p>目前对于 LLM 的量化方案基本都是在 <code>matmul</code> 这一步进行的。在 Llama-2 系列模型中，一共有 6 处 <code>matmul</code> 运算，分别是（命名规范请参考 <code>transformers</code> library）：</p>
<ul>
<li><code>self_attn.vqk_proj.weight</code></li>
<li><code>self_attn.o_proj.weight</code></li>
<li><code>mlp.gate_proj.weight</code></li>
<li><code>mlp.down_proj.weight</code></li>
<li><code>mlp.up_proj.weight</code></li>
<li><code>lm_head.weight</code></li>
</ul>
<p>其中前 5 处在每个 Attention block 中都会出现，最后一处则是在最后计算 logits 时才会出现。</p>
<p>考虑到系统硬件的设计，计算过程中的 weights &amp; activations 大多数采用 <code>fp32</code> (single precision) 或 <code>fp16</code> (half precision) 来存储。对于以 <code>fp32</code> 格式存储 weights 的模型，推理阶段使用 <code>fp16</code> 就是最 naive 的一种 quantization, 并且效果基本不会差。原因是 <code>fp32</code> 转换到 <code>fp16</code> 的过程中，浮点数舍入误差并不大，而最后 decode 时只对 logits 取 top-1 (or top-k), 所以这个误差基本是可以忽略不计的。</p>
<p>然而，当每个参数的比特数变为 8bit 甚至更低 (4bit, 2bit, <a href="https://arxiv.org/abs/2402.17764">1.58bit</a>) 时，误差就会大很多了。如何做到更低比特的 quantization 呢？</p>
<blockquote>
<p>有人会问，既然有 8bit 和 16bit, 为什么不考虑它们中间的 10bit, 12bit, &hellip; 呢？</p>
<p>大概因为目前的这些 GPU 架构，最小寻址单元就是 8bit 吧，例如 10bit 其实也会被 cast 成更高的 16bit 才能参与后续计算，这里的计算开销并不小。所以，工程上没有太大的意义。</p>
</blockquote>
<p>LLM 社区对 quantize 的研究和探索非常广泛，这里简单列举一些工作：</p>
<ul>
<li><a href="https://arxiv.org/abs/2210.17323">GPTQ</a>: 我很喜欢它的 Math formulation.</li>
<li><a href="https://arxiv.org/abs/2306.00978">AWQ</a>: Song Han 的工作，也是 MLSys 2024 Best Paper Award, 值得一读。这篇文章的两个 key point 是：(1) 对量化误差而言，参数并不是同等重要的 (2) 应当根据 activation value 而非 weight value 来找到那些重要的参数。</li>
<li><a href="https://github.com/ggml-org/llama.cpp">llama.cpp</a>: 它实现了非常多的 quantize 方法，并且是无外部依赖、pure C++ 的实现，对于学习 LLM 和本地部署 LLM 都很有用。</li>
</ul>
<p>此外，评估量化结果的好坏，最先需要考虑的是如下两个 metric:</p>
<ul>
<li>MSE loss: 衡量 quantize 前后 weight matrix 的差异</li>
<li>PPL: 评估 LLM 性能的很重要的 metric, 不多说了</li>
</ul>
<p>当然，只测这俩肯定是不够的。还是得跑一些大的 benchmark 来看看和原始模型的差异有多大。</p>
<p>接下来，我们配合代码讲一讲我做的一些尝试。Config:</p>
<ul>
<li>Model: llama-2-7b-chat-hf</li>
<li>Pure PyTorch + AutoRT implementation, without <code>transformers</code> or other high level libraries</li>
<li>RTX 3090</li>
<li>Max sequence length: 512</li>
</ul>
<h2 id="naive-quantization">Naive Quantization<a hidden class="anchor" aria-hidden="true" href="#naive-quantization">#</a></h2>
<p>我们试图做的是 8bit quantization. 由于 CUDA backend 本身不支持 <code>fp8</code> (其实现在也有啦), 所以折中的策略是：用 <code>fp16</code> 计算 activation value, 用 <code>int8</code> 存储 quantized weights, 并在 dequantize 阶段通过一些操作将其转换为 <code>fp16</code> 或 <code>fp32</code>, 再与 activation value 进行 <code>matmul</code> 计算。</p>
<p>我们首先对 weights 进行观察。有两个有趣的现象：</p>
<ul>
<li>它们的绝对值基本都很小</li>
<li>它们近似呈现正态分布（此外，不同层、不同作用的 weights 往往具有不同的 sigma）</li>
</ul>
<p>针对现象 1, 一个自然的想法是：在 [-1, 1] 区间内指定 256 个浮点数。Quant 阶段，把每个 weight 映射到离它最近的那个浮点数，并记录下 int8 格式的 index. Dequant 阶段，根据 index 在 lookup table 中查到对应的浮点数，并复原回 <code>fp32/fp16</code> 即可。</p>
<p>写成数学公式。我们假设 weights 是一维 tensor, 长度是 N. (实际上应该是 2d 矩阵，但是可以 flatten 到 1d)</p>
<p><code>Quant</code>:</p>
<ul>
<li>Input: weights <code>w[N] (fp32)</code>, lookup table <code>a[0..255] (fp32)</code></li>
<li>for each <code>w[i]</code>:
<ul>
<li>if <code>w[i] &gt;= 1</code>: let <code>id = 255</code>;</li>
<li>else if <code>w[i] &lt; -1</code>: let <code>id = 0</code>;</li>
<li>else: find <code>id in [0, 255]</code> s.t. <code>a[id] &lt;= w[i] &lt; a[id+1]</code>.</li>
</ul>
</li>
<li>Output: <code>id[N] (int8)</code></li>
</ul>
<p><code>Dequant</code>:</p>
<ul>
<li>Input: quantized weights <code>id[N] (int8)</code>, lookup table <code>a[0..255] (fp32)</code></li>
<li>Output: <code>_w[i] = a[id[i]] (fp32)</code></li>
</ul>
<p>其中由于 <code>id</code> 作为 int8 的 range 是 [-128, 127], 负数并不应该作为 tensor index. 所以实际上需要先转换成 uint8 (unsigned char) 来移动到正确的 [0, 255] 区间。算法过程中为了简洁没有写这步符号转换。下同。</p>
<p>对于 <code>a[]</code> 的选取，最简单的策略是均匀划分 [-1, 1] 区间。另一种策略是，由于 weights 呈现正态分布，所以按照正态分布的分位数点进行不均匀的划分 (可以参考 llama.cpp 中的 <code>iq</code> 量化策略)。我当时测了一下后者，发现虽然做不到 8bit quant, 但是 12bit (也就是 <code>a.len() == 4096</code>) 还是绰绰有余的。</p>
<h2 id="blockwise-quantization">Blockwise Quantization<a hidden class="anchor" aria-hidden="true" href="#blockwise-quantization">#</a></h2>
<p>反思一下上述策略做不到 8bit 的原因。我们对所有参数都采用了同样的 cast range, 然而参数间的差异仍然是非常大的。例如可能某一段参数都集中在 <code>[-1e-5, 1e-5]</code> 区间内，这时采用 256 个预先定好的数对其进行舍入，它们可能都会被 quantize 到同一个值上——因为 $\frac{1}{256}$ 大约是 <code>3e-3</code>. 比这些参数大了两个数量级。</p>
<p>所以，我们可以对参数进行分块，每块采取不同的 cast range. 例如，每 32 个数作为一个 block. 在每个 block 内部计算 <code>weights.abs().max()</code>, 然后把所有 weights normalize 到 [-1, 1] 区间，再进行 quantize.</p>
<p><code>Quant</code>:</p>
<ul>
<li>Input: weights <code>w[N] (fp32)</code>, lookup table <code>a[0..255] (fp32)</code></li>
<li>slice <code>w[N]</code> into <code>K</code> blocks <code>wk[]</code>, each of size <code>32</code></li>
<li>for each <code>wk[]</code>:
<ul>
<li>let <code>scale = wk.abs().max()</code></li>
<li><code>wk = wk / scale</code></li>
<li>for each <code>wk[i]</code>:
<ul>
<li>cast <code>wk[i]</code> into <code>id</code> s.t. <code>a[id] &lt;= wk[i] &lt; a[id+1]</code></li>
</ul>
</li>
</ul>
</li>
<li>Output: <code>id[N] (int8)</code> and <code>scales[N/32] (fp32)</code></li>
</ul>
<p><code>Dequant</code>:</p>
<ul>
<li>Input: quantized weights <code>id[N] (int8)</code>, lookup table <code>a[0..255] (fp32)</code> and <code>scales[N/32] (fp32)</code></li>
<li>Output: <code>_w[i] = a[id[i]] * scales[i/32]</code></li>
</ul>
<p>这种方法，其实对应了 llama.cpp 中的 <code>q8_0</code>. 此时压缩率不再是正正好好的 2.0 (假设原本是 <code>fp16</code>, 现在是 <code>int8</code>). 这是因为我们需要额外存储辅助数组 <code>scale</code>. 然而，每 32 个 weights 才对应一个 scale, 其实也是比较小的规模。</p>
<p>但是，如果直接这么做，模型的输出仍然不太好。什么原因呢？</p>
<p>回顾当初，我们使用 [-1, 1] 作为 cast range 是因为 weights 满足近似正态分布的假设，也就是正值和负值出现的概率相似，或者说均值接近 0. 然而，当我们分成大小为 32 的块之后，这个假设就显得不太恰当了。我们应当使用不同的方法进行 normalization.</p>
<p>不过话又说回来了，32 一组的采样是比较小的，如果样本数达到 1024, 是不是又可以保证近似正态假设了呢？</p>
<h2 id="biased-blockwise-quantization">Biased Blockwise Quantization<a hidden class="anchor" aria-hidden="true" href="#biased-blockwise-quantization">#</a></h2>
<p>作为上述方法的修正，我们不但记录 <code>scale</code>, 还记录区间最小值 <code>min_val</code>. 也就是说：</p>
<ul>
<li><code>min_val = wk.min()</code></li>
<li><code>scale = wk.max() - min_val</code></li>
<li><code>wk &lt;- (wk - min_val) / scale</code></li>
</ul>
<p>这样使得变换后的 <code>wk[]</code> 位于 [0, 1] 之间，再采用上述量化策略即可。这对应 llama.cpp 中的 <code>q8_1</code>.</p>
<h2 id="another-hardware-efficient-approach">Another Hardware Efficient Approach<a hidden class="anchor" aria-hidden="true" href="#another-hardware-efficient-approach">#</a></h2>
<p>上述方法其实是按照待量化矩阵 <code>w</code> 的内存连续性进行了分块。一般也不会把 block_size 取成 32 这么小，1024 甚至 4096 基本也是能 work 的。如果为了写 kernel 时比较方便，也可以取成 <code>block_size = w.size(1)</code>, 也就是一行分为一组，这样或许更直观。</p>
<p>当然，其实我们还有另一种分块策略。由于 <code>w</code> 是 2d tensor, 所以不妨划分成若干个 <code>KxK</code> 的子矩阵块。这样其实和 <code>matmul</code> 的分块加速是比较兼容的，或许更适合硬件执行（我乱说的）。</p>
<h2 id="experiments">Experiments<a hidden class="anchor" aria-hidden="true" href="#experiments">#</a></h2>
<p>我们把 <code>K</code> 改记为步长 stride, 利用 AutoRT 简单实现一下 dequantize kernel:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>device <span style="color:#f92672">=</span> autort<span style="color:#f92672">.</span>device()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>value_map <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">3.90625e-3</span> <span style="color:#f92672">*</span> x <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">256</span>)], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>value_map_gpu <span style="color:#f92672">=</span> value_map<span style="color:#f92672">.</span>to(autort<span style="color:#f92672">.</span>device())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sm_table <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span>stride <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>table_lookup <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;o_proj&#34;</span>: <span style="color:#e6db74">&#34;self_attn.o_proj.weight&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;gate_proj&#34;</span>: <span style="color:#e6db74">&#34;mlp.gate_proj.weight&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;down_proj&#34;</span>: <span style="color:#e6db74">&#34;mlp.down_proj.weight&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;up_proj&#34;</span>: <span style="color:#e6db74">&#34;mlp.up_proj.weight&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;vqk_proj&#34;</span>: <span style="color:#e6db74">&#34;self_attn.vqk_proj.weight&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;weight_classify&#34;</span>: <span style="color:#e6db74">&#34;lm_head.weight&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">weight_preprocess</span>(w: torch<span style="color:#f92672">.</span>Tensor, name: str):
</span></span><span style="display:flex;"><span>  original_shape <span style="color:#f92672">=</span> w<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>  w <span style="color:#f92672">=</span> w<span style="color:#f92672">.</span>unfold(<span style="color:#ae81ff">0</span>, stride, stride)<span style="color:#f92672">.</span>unfold(<span style="color:#ae81ff">1</span>, stride, stride)
</span></span><span style="display:flex;"><span>  n0, n1 <span style="color:#f92672">=</span> w<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), w<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>  w <span style="color:#f92672">=</span> w<span style="color:#f92672">.</span>reshape(n0, n1, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>) <span style="color:#75715e"># [n0, n1, stride * stride]</span>
</span></span><span style="display:flex;"><span>  w_min <span style="color:#f92672">=</span> w<span style="color:#f92672">.</span>min(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)[<span style="color:#ae81ff">0</span>] <span style="color:#75715e"># [n0, n1, 1]</span>
</span></span><span style="display:flex;"><span>  w_max <span style="color:#f92672">=</span> w<span style="color:#f92672">.</span>max(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)[<span style="color:#ae81ff">0</span>] <span style="color:#75715e"># [n0, n1, 1]</span>
</span></span><span style="display:flex;"><span>  scale <span style="color:#f92672">=</span> w_max <span style="color:#f92672">-</span> w_min
</span></span><span style="display:flex;"><span>  w <span style="color:#f92672">=</span> (w <span style="color:#f92672">-</span> w_min) <span style="color:#f92672">/</span> scale <span style="color:#75715e"># [n0, n1, stride * stride]</span>
</span></span><span style="display:flex;"><span>  w_low <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>bucketize(w, value_map[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>int8)<span style="color:#f92672">.</span>view(n0, n1, stride, stride)<span style="color:#f92672">.</span>permute(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>)<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">*</span>original_shape)
</span></span><span style="display:flex;"><span>  sm_table[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">.scale&#34;</span>] <span style="color:#f92672">=</span> scale<span style="color:#f92672">.</span>view(n0, n1)<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>  sm_table[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">.min&#34;</span>] <span style="color:#f92672">=</span> w_min<span style="color:#f92672">.</span>view(n0, n1)<span style="color:#f92672">.</span>to(torch<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> w_low
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>my_custom_fn <span style="color:#f92672">=</span> autort<span style="color:#f92672">.</span>export(ir<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  w[M, K] = value_map_gpu[input1[M, K].unsigned_cast()]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  my_result[M] +=! input0[K] * (w[M, K] * scale[M/</span><span style="color:#e6db74">{</span>stride<span style="color:#e6db74">}</span><span style="color:#e6db74">, K/</span><span style="color:#e6db74">{</span>stride<span style="color:#e6db74">}</span><span style="color:#e6db74">] + min_val[M/</span><span style="color:#e6db74">{</span>stride<span style="color:#e6db74">}</span><span style="color:#e6db74">, K/</span><span style="color:#e6db74">{</span>stride<span style="color:#e6db74">}</span><span style="color:#e6db74">])
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>, inputs<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;input0=float32[K]&#34;</span>, <span style="color:#e6db74">&#34;input1=int8[M, K]&#34;</span>, <span style="color:#e6db74">&#34;min_val=float32[A, B]&#34;</span>, <span style="color:#e6db74">&#34;scale=float32[A, B]&#34;</span>, <span style="color:#e6db74">&#34;value_map_gpu=float32[L]&#34;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">matmul_dequat</span>(x, w, name, layer, memory_out<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>  <span style="color:#75715e"># parse name</span>
</span></span><span style="display:flex;"><span>  name <span style="color:#f92672">=</span> table_lookup[name]
</span></span><span style="display:flex;"><span>  name <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;model.layers.</span><span style="color:#e6db74">{</span>layer<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span> <span style="color:#66d9ef">if</span> layer <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">0</span> <span style="color:#66d9ef">else</span> name
</span></span><span style="display:flex;"><span>  scale <span style="color:#f92672">=</span> sm_table[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">.scale&#34;</span>]<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>  min_val <span style="color:#f92672">=</span> sm_table[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">.min&#34;</span>]<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>  memory_out <span style="color:#f92672">=</span> memory_out <span style="color:#66d9ef">if</span> memory_out <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span> <span style="color:#66d9ef">else</span> torch<span style="color:#f92672">.</span>empty([w<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)], dtype<span style="color:#f92672">=</span>x<span style="color:#f92672">.</span>dtype, device<span style="color:#f92672">=</span>x<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> my_custom_fn(x, w, min_val, scale, value_map_gpu, memory_out<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>), out<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(token, pos):
</span></span><span style="display:flex;"><span>  x <span style="color:#f92672">=</span> token_embedding_table<span style="color:#f92672">.</span>select(<span style="color:#ae81ff">0</span>, token)<span style="color:#f92672">.</span>view(<span style="color:#ae81ff">1</span>, dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> l <span style="color:#f92672">in</span> range(n_layers):
</span></span><span style="display:flex;"><span>    xb <span style="color:#f92672">=</span> rmsnorm(x, rms_att_w[l])
</span></span><span style="display:flex;"><span>    local_cache <span style="color:#f92672">=</span> val_cache<span style="color:#f92672">.</span>select(<span style="color:#ae81ff">0</span>, l)<span style="color:#f92672">.</span>narrow(<span style="color:#ae81ff">0</span>, pos, <span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>    matmul_dequat(xb, weight_vqk[l], <span style="color:#e6db74">&#34;vqk_proj&#34;</span>, l, memory_out<span style="color:#f92672">=</span>local_cache<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> xb<span style="color:#f92672">.</span>size(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)))
</span></span><span style="display:flex;"><span>    sq, sk <span style="color:#f92672">=</span> local_cache[<span style="color:#ae81ff">1</span>], local_cache[<span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    sq_out <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>empty_like(sq)<span style="color:#f92672">.</span>view(n_heads, head_size)
</span></span><span style="display:flex;"><span>    sk_out <span style="color:#f92672">=</span> key_cache<span style="color:#f92672">.</span>select(<span style="color:#ae81ff">0</span>, l)<span style="color:#f92672">.</span>narrow(<span style="color:#ae81ff">0</span>, pos, <span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>view(n_heads, head_size)
</span></span><span style="display:flex;"><span>    autort<span style="color:#f92672">.</span>ops<span style="color:#f92672">.</span>rotary_f32(sq<span style="color:#f92672">.</span>view(n_heads, <span style="color:#ae81ff">2</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>), inv_freq, sq_out, extra<span style="color:#f92672">=</span>[pos,])
</span></span><span style="display:flex;"><span>    autort<span style="color:#f92672">.</span>ops<span style="color:#f92672">.</span>rotary_f32(sk<span style="color:#f92672">.</span>view(n_heads, <span style="color:#ae81ff">2</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>), inv_freq, sk_out, extra<span style="color:#f92672">=</span>[pos,])
</span></span><span style="display:flex;"><span>    sq, sk <span style="color:#f92672">=</span> sq_out, sk_out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    b_sq <span style="color:#f92672">=</span> sq<span style="color:#f92672">.</span>view(n_heads, head_size)
</span></span><span style="display:flex;"><span>    b_sk <span style="color:#f92672">=</span> key_cache<span style="color:#f92672">.</span>select(<span style="color:#ae81ff">0</span>, l)<span style="color:#f92672">.</span>view(seq_len, n_heads, head_size)<span style="color:#f92672">.</span>narrow(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, pos <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    b_sv <span style="color:#f92672">=</span> val_cache<span style="color:#f92672">.</span>select(<span style="color:#ae81ff">0</span>, l)<span style="color:#f92672">.</span>view(seq_len, n_heads, head_size)<span style="color:#f92672">.</span>narrow(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, pos <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    xb <span style="color:#f92672">=</span> autort<span style="color:#f92672">.</span>ops<span style="color:#f92672">.</span>attention_f32(b_sq, b_sk, b_sv, att_f)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    xb <span style="color:#f92672">=</span> matmul_dequat(xb, weight_o[l], <span style="color:#e6db74">&#34;o_proj&#34;</span>, l)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> xb
</span></span><span style="display:flex;"><span>    xb <span style="color:#f92672">=</span> rmsnorm(x, rms_ffn_w[l])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    xb <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>functional<span style="color:#f92672">.</span>silu(matmul_dequat(xb, weight_f1[l], <span style="color:#e6db74">&#34;gate_proj&#34;</span>, l)) <span style="color:#f92672">*</span> matmul_dequat(xb, weight_f3[l], <span style="color:#e6db74">&#34;up_proj&#34;</span>, l)
</span></span><span style="display:flex;"><span>    xb <span style="color:#f92672">=</span> matmul_dequat(xb, weight_f2[l], <span style="color:#e6db74">&#34;down_proj&#34;</span>, l)
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> xb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  x <span style="color:#f92672">=</span> rmsnorm(x, rms_end_w)
</span></span><span style="display:flex;"><span>  logits <span style="color:#f92672">=</span> matmul_dequat(x, weight_classify, <span style="color:#e6db74">&#34;weight_classify&#34;</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> logits<span style="color:#f92672">.</span>half()
</span></span></code></pre></div><p>类似也可以实现一个不带 <code>min_val</code> 的版本。</p>
<p>接下来，我们试着取不同的 stride (16, 32, 64), 看看模型的表现。</p>
<p>Prompt: <code>&quot;The Atlantic Ocean is&quot;</code></p>
<p>下面 <code>q8_1</code> 指的是含有 <code>scale</code> 和 <code>min_val</code> 的有偏方法，<code>q8_0</code> 指的是只含有 <code>scale</code> 的无偏方法。</p>
<hr>
<p><strong>stride = 16, <code>q8_1</code></strong>: 7.69 tokens/s</p>
<p>The Atlantic Ocean is the second largest ocean in the world, covering approximately 20% of the Earth&rsquo;s surface. It is located between the Americas and Europe and Africa, and it separates the continents of North and South America from Europe and Africa. The Atlantic Ocean is a major component of the global ocean system and plays a crucial role in the Earth&rsquo;s climate and weather patterns.
The Atlantic Ocean is bounded by several major ocean currents, including the Gulf Stream, which brings warm water from the equator to the northern hemisphere, and the North Atlantic Current, which helps to moderate the climate of Western Europe. The ocean is also home to several major ocean basins, including the Caribbean Sea, the Gulf of Mexico, and the Mediterranean Sea.
The Atlantic Ocean is a vital source of food, with many countries relying on its fisheries for their economic well-being. It is also an important transportation route, with many ports and harbors providing access to the ocean for trade and commerce.
The Atlantic Ocean has a diverse range of marine life, including whales, dolphins, turtles, and many species of fish. It is also home to several important marine ecosystems, including coral reefs, estuaries, and mangrove forests.
However, the Atlantic Ocean is facing several environmental challenges, including pollution, overfishing, and the impacts of climate change. Rising ocean temperatures and acidification are affecting marine ecosystems and the animals that depend on them, and plastic pollution is accumulating in the ocean and harming marine life.
Overall, the Atlantic Ocean is a vital and complex system that plays a crucial role in the Earth&rsquo;s climate and weather patterns, as well as in the economic and cultural well-being of many countries around the world.</p>
<hr>
<p><strong>stride = 32, <code>q8_1</code></strong>: 10.63 tokens/s</p>
<p>The Atlantic Ocean is the second largest ocean in the world, covering approximately 20% of the Earth&rsquo;s surface. It is located between the Americas and Europe and Africa, and it separates the continents of North and South America from Europe and Africa. The Atlantic Ocean is a major component of the Earth&rsquo;s climate system and plays a crucial role in regulating global weather patterns, ocean currents, and marine ecosystems.
The Atlantic Ocean is bounded by several major ocean currents, including the Gulf Stream, which originates in the Gulf of Mexico and flows northward along the eastern coast of the United States and Canada, and the North Atlantic Current, which flows southward along the western coast of Europe. These currents play a significant role in shaping the climate of the regions they affect, and they are also important for the transport of heat and nutrients across the ocean.
The Atlantic Ocean is home to a diverse range of marine life, including many species of fish, whales, dolphins, and other marine mammals. The ocean&rsquo;s waters are also home to a variety of coral reefs, kelp forests, and other marine ecosystems that provide important habitats for many species of fish and other marine organisms.
The Atlantic Ocean has a long history of human exploration and settlement, with many ancient civilizations establishing trade routes and colonies along its shores. Today, the Atlantic Ocean is an important source of food, transportation, and recreation for millions of people around the world.
Some of the key features of the Atlantic Ocean include:</p>
<ul>
<li>The Gulf Stream, a warm ocean current that flows northward along the eastern coast of the United States and Canada</li>
<li>The North Atlantic Current, a cold ocean current that flows southward along the western coast of Europe</li>
<li>The Mid-Atlantic Ridge, a mountain range that runs along the center of the Atlantic Ocean, where new ocean crust is being created as the tectonic plates move apart</li>
<li>The Canary Current, a warm ocean current that flows eastward across the Atlantic Ocean from the Gulf of Mexico</li>
<li>The Brazil Current, a warm ocean current that flows southward along the eastern coast of South America</li>
<li>The South Atlantic Gyre, a large-scale circulation of ocean water that flows clockwise in the southern hemisphere</li>
<li>The North Atlantic Gyre, a large</li>
</ul>
<hr>
<p><strong>stride = 64, <code>q8_1</code></strong>: 11.93 tokens/s</p>
<p>The Atlantic Ocean is the second largest ocean in the world, covering approximately 20% of the Earth&rsquo;s surface. The Atlantic Ocean is located between the Americas and Europe and Africa, and it connects with the Indian and Arctic Oceans to the east and the Pacific Ocean to the west. The Atlantic Ocean is a major component of the Earth&rsquo;s climate system and plays a significant role in the global ocean circulation.
The Atlantic Ocean is divided into several sections, including the:</p>
<ul>
<li>North Atlantic Ocean: This section extends from the Arctic Ocean to the equator and includes the waters off the coasts of North America, Europe, and Africa.</li>
<li>South Atlantic Ocean: This section extends from the equator to the Antarctic Ocean and includes the waters off the coasts of South America, Africa, and Australia.</li>
<li>Caribbean Sea: This is a smaller section of the Atlantic Ocean located between the Gulf of Mexico and the Virgin Islands.</li>
<li>Gulf of Mexico: This is a smaller section of the Atlantic Ocean located between the Yucatan Peninsula and the Florida Panhandle.</li>
</ul>
<p>The Atlantic Ocean is home to a diverse range of marine life, including:</p>
<ul>
<li>Whales: Several species of whales, including humpback, blue, and fin whales, can be found in the Atlantic Ocean.</li>
<li>Dolphins: Bottlenose dolphins, orcas, and other species can be found in the Atlantic Ocean.</li>
<li>Fish: The Atlantic Ocean is home to a wide variety of fish, including tuna, mackerel, and herring.</li>
<li>Sharks: Several species of sharks, including great whites, tiger sharks, and hammerheads, can be found in the Atlantic Ocean.</li>
</ul>
<p>The Atlantic Ocean has a significant impact on the climate and weather patterns of the surrounding land masses. The Gulf Stream, a warm ocean current, plays a major role in the climate of Western Europe, while the North Atlantic Ocean is known for its harsh winters and storms.</p>
<p>（接下来不停地输出换行符）</p>
<hr>
<p><strong>stride = 16, <code>q8_0</code></strong>: 11.75 tokens/s</p>
<p>The Atlantic Ocean is the second largest ocean in the world, covering approximately 20% of the Earth&rsquo;s surface. The Atlantic Ocean is located between the Americas and Europe and Africa, and it connects with the Indian and Arctic Oceans to the east and the Pacific Ocean to the west. The Atlantic Ocean is a vital component of the Earth&rsquo;s climate system, and it plays a significant role in regulating the planet&rsquo;s weather patterns, ocean currents, and marine ecosystems.
The Atlantic Ocean is divided into several sections, including the:</p>
<ol>
<li>North Atlantic Ocean: This section extends from the Arctic Ocean to the equator and includes the waters off the coasts of Europe, Africa, and North America.</li>
<li>South Atlantic Ocean: This section extends from the equator to the Antarctic Ocean and includes the waters off the coasts of South America, Africa, and Australia.</li>
<li>Caribbean Sea: This is a smaller section of the Atlantic Ocean located between the Gulf of Mexico and the coast of South America.</li>
<li>Gulf of Mexico: This is a smaller section of the Atlantic Ocean located off the coast of North America.
The Atlantic Ocean is home to a diverse range of marine life, including whales, dolphins, sharks, and many species of fish. The ocean&rsquo;s currents and tides play a crucial role in shaping the coastlines of the surrounding landmasses, and they also help to distribute heat and nutrients throughout the ocean.
The Atlantic Ocean has a long history of human exploration and settlement, with many ancient civilizations establishing trade routes and colonies along its shores. Today, the Atlantic Ocean is an important source of food, transportation, and recreation for millions of people around the world.
The Atlantic Ocean is also a vital component of the Earth&rsquo;s climate system, and it plays a significant role in regulating the planet&rsquo;s weather patterns and climate. The ocean&rsquo;s currents help to distribute heat and nutrients throughout the ocean, and they also play a role in the formation of hurricanes and other severe weather events.
Overall, the Atlantic Ocean is a vast and complex body of water that plays a vital role in the Earth&rsquo;s climate system and ecosystem. Its diverse marine life, rich history, and ongoing importance to human society make it a fascinating and important feature</li>
</ol>
<hr>
<p><strong>stride = 32, <code>q8_0</code></strong>: 13.40 tokens/s</p>
<p>The Atlantic Ocean is the second-largest ocean in the world, covering an area of approximately 106,400,000 square kilometers (41,000,000 square miles). It is located between the Americas and Europe and Africa, and it connects with the Indian and Arctic Oceans to the east.
The Atlantic Ocean is bound by several major ocean currents, including the Gulf Stream, which originates in the Gulf of Mexico and flows northward along the eastern coast of the United States and Canada, and the North Atlantic Current, which flows southward along the western coast of Europe.
The Atlantic Ocean is home to a diverse range of marine life, including whales, dolphins, sharks, and many species of fish. The ocean&rsquo;s waters are also rich in nutrients, including nitrogen and phosphorus, which support the growth of phytoplankton and other marine plants.
The Atlantic Ocean has played a significant role in shaping the Earth&rsquo;s climate and weather patterns. The ocean&rsquo;s warm waters help to regulate the Earth&rsquo;s temperature, and the Gulf Stream&rsquo;s influence on the climate of Western Europe has been particularly significant.
The Atlantic Ocean has also been the site of many significant historical events, including the discovery of the New World, the colonization of the Americas, and the transatlantic slave trade. Today, the ocean continues to be an important route for international trade and transportation, and it is a popular destination for tourists and recreational boaters.
Overall, the Atlantic Ocean is a vast and complex body of water that plays a critical role in the Earth&rsquo;s climate and weather patterns, as well as in human history and culture.</p>
<hr>
<p><strong>stride = 64, <code>q8_0</code></strong>: 生成乱码，速度无意义</p>
<p>The Atlantic Ocean is the second-larg Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py Py</p>
<hr>
<p><strong>Baseline: Quantize-Free Inference</strong>: 47.60 tokens/s</p>
<p>The Atlantic Ocean is the second largest ocean in the world, covering approximately 20% of the Earth&rsquo;s surface. It is located between the Americas and Europe and Africa, and it separates the continents of North and South America from Africa and Europe. The Atlantic Ocean is a vital component of the Earth&rsquo;s climate system and plays a crucial role in regulating global weather patterns, ocean currents, and marine ecosystems.
The Atlantic Ocean is home to a diverse range of marine life, including whales, dolphins, turtles, and a vast array of fish species. The ocean&rsquo;s waters are also rich in nutrients, including nitrogen, phosphorus, and iron, which support the growth of phytoplankton and other microorganisms. These microorganisms, in turn, support the entire marine food chain, from tiny zooplankton to large predators like sharks and tuna.
The Atlantic Ocean has a significant impact on the Earth&rsquo;s climate, particularly in regulating global temperatures and weather patterns. The ocean acts as a heat sink, absorbing and storing heat from the sun, which helps to moderate temperatures around the world. The ocean also plays a key role in the Earth&rsquo;s water cycle, evaporating water vapor into the atmosphere, which eventually falls as rain or snow.
In addition to its ecological importance, the Atlantic Ocean has significant economic and cultural value. The ocean provides a source of food, including fish and other seafood, which are an important part of the diets of millions of people around the world. The ocean also supports a variety of industries, including shipping, tourism, and offshore energy production.
However, the Atlantic Ocean is facing a range of threats, including pollution, overfishing, and the impacts of climate change. Plastic pollution, in particular, is a major problem in the Atlantic, with millions of tons of plastic waste entering the ocean each year, harming marine life and contaminating the food chain. Overfishing is also a significant issue, with many fish populations being depleted due to unsustainable fishing practices.
Climate change is also having a significant impact on the Atlantic Ocean, with rising temperatures and acidification of the water affecting marine ecosystems and the organisms that live in them. Rising sea</p>
<hr>
<p><strong>Baseline: <code>transformers</code> Native Inference</strong>: 162.89 tokens/s</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoModelForCausalLM, AutoTokenizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/data1/zhiyang/models/llama-2-7b-chat-hf&#39;</span>
</span></span><span style="display:flex;"><span>device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda:0&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> AutoTokenizer<span style="color:#f92672">.</span>from_pretrained(path)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> AutoModelForCausalLM<span style="color:#f92672">.</span>from_pretrained(path, torch_dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float16)<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prompt <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;The Atlantic Ocean&#34;</span>
</span></span><span style="display:flex;"><span>start_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>input_ids <span style="color:#f92672">=</span> tokenizer(prompt, return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pt&#34;</span>)<span style="color:#f92672">.</span>input_ids<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>generate(input_ids, max_length<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>)
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>decode(output[<span style="color:#ae81ff">0</span>], skip_special_tokens<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>end_time <span style="color:#f92672">=</span> time<span style="color:#f92672">.</span>time()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(result)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>len(result) <span style="color:#f92672">/</span> (end_time <span style="color:#f92672">-</span> start_time)<span style="color:#e6db74">}</span><span style="color:#e6db74"> tokens/s&#34;</span>)
</span></span></code></pre></div><p>注意：这里没有使用 <code>flash-attention</code> kernel. 如果加上 <code>attn_implementation=&quot;flash_attention_2&quot;</code>, 在 512 的 sequence length 上反而速度只有 ~130 tokens/s, 大概是因为 flash-attn 还是更适合 Hopper 架构，对 3090 这样的老古董 device 并没有很好的优化吧。当然，flash-attn 本来就更适合长文本的情形，这里就不测了。之后另写一篇测评吧。</p>
<p>The Atlantic Ocean is the second largest ocean in the world, covering approximately 20% of the Earth&rsquo;s surface. It is located between the Americas and Europe and Africa, and it separates the continents of North and South America from Europe and Africa. The Atlantic Ocean is a vital component of the Earth&rsquo;s climate system and plays a crucial role in regulating global weather patterns, ocean currents, and marine ecosystems.</p>
<p>The Atlantic Ocean is home to a diverse range of marine life, including whales, dolphins, turtles, and a vast array of fish species. The ocean&rsquo;s waters are also rich in nutrients, including nitrogen, phosphorus, and iron, which support the growth of phytoplankton and other microorganisms. These microorganisms form the base of the ocean&rsquo;s food web, supporting a vast array of marine life.</p>
<p>The Atlantic Ocean has a significant impact on the Earth&rsquo;s climate, playing a key role in the global water cycle and influencing weather patterns around the world. The ocean&rsquo;s currents help to distribute heat and moisture across the globe, and its thermohaline circulation (THC) plays a crucial role in regulating global climate patterns. The THC is a complex system of ocean currents that helps to distribute heat and nutrients around the globe, and it is thought to be one of the key factors influencing global climate patterns.</p>
<p>The Atlantic Ocean has a long and complex history, with evidence of human activity dating back thousands of years. The ocean has played a significant role in the development of human civilization, with many ancient cultures relying on its resources for food, transportation, and trade. Today, the Atlantic Ocean continues to be an important source of food, energy, and transportation, with many countries relying on its resources for their economic well-being.</p>
<p>Despite its importance, the Atlantic Ocean is facing a range of environmental challenges, including pollution, overfishing, and the impacts of climate change. Plastic pollution in particular is a major problem, with millions of tons of plastic waste entering the ocean every year, harming marine life and contaminating the food chain. Overfishing is also a significant issue, with many fish stocks being overexploited and depleted, leading to the collapse of fisheries</p>
<hr>
<p>给生成速度打个表（单位 token/s）</p>
<table>
<thead>
<tr>
<th></th>
<th>stride=16</th>
<th>stride=32</th>
<th>stride=64</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>q8_0</code></td>
<td>11.75</td>
<td>13.40</td>
<td>-</td>
</tr>
<tr>
<td><code>q8_1</code></td>
<td>7.69</td>
<td>10.63</td>
<td>11.93</td>
</tr>
</tbody>
</table>
<p>明显可见 <code>q8_0</code> 比 <code>q8_1</code> 推理速度更快，但是 <code>q8_0</code> 在 <code>stride=64</code> 时就寄了，反观 <code>q8_1</code> 还能打。</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>这篇文章主要在靠最后的实验输出凑字数（笑）。实验结论也并不太出乎意料，当然速度上没有进行任何优化，所以距离 <code>transformers</code> 的版本仍然有 10x 的差距。但是有趣的地方大概在于自己实现这些个算法的成就感吧！GPTQ int4 量化的版本在这里 <a href="https://github.com/microsoft/antares/blob/latest/samples/05_llama2_7b_int4.py">link</a>. 最后强推一下 <a href="https://github.com/microsoft/antares">AutoRT</a> ！如果有手搓 customized kernel 的需求，又觉得 Triton/CUDA 太麻烦，不如试试它 :)</p>
<p>此外，最近其实和不少人探讨了这个问题，也就是算法和系统上的 trade-off. 搞算法的人设计出好多妙妙算法，但是未必能在系统上高效实现，从而也就未必能很好地落地。像最近的一些我觉得比较 impressive 的工作 (<a href="https://arxiv.org/abs/2312.06635">GLA</a>, <a href="https://arxiv.org/abs/2412.19437">MLA</a>, <a href="https://arxiv.org/abs/2502.11089">NSA</a> 等等) 都感觉像是 algorithm 在 system/hardware 戴的镣铐下跳舞，或者说 algorithm 是在 &ldquo;align&rdquo; 到 hardware efficient design. 这样的算法设计一定是最优的吗？不一定，甚至可能一定不。事实上现在所有这些名声在外的 network design (Convolution, Residual, Attention, &hellip;) 哪个是 &ldquo;Optimal&rdquo; 的呢？一个都不是呀！（打个比方，难道人脑会自动算 <code>matmul</code> 吗？）</p>
<p>只不过 ML 发展的历程就是这样的。既然现在 hardware 的能力 (memory, bandwidth, &hellip;) 已经赶不上模型 scale-up 的速度了，那么顺应当下客观规律的做法就是 hardware-efficient algorithm design 了吧。</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/llm/">Llm</a></li>
      <li><a href="http://localhost:1313/tags/code/">Code</a></li>
      <li><a href="http://localhost:1313/tags/system/">System</a></li>
      <li><a href="http://localhost:1313/tags/quant/">Quant</a></li>
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLM Quantization on x"
            href="https://x.com/intent/tweet/?text=LLM%20Quantization&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f&amp;hashtags=llm%2ccode%2csystem%2cquant">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLM Quantization on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f&amp;title=LLM%20Quantization&amp;summary=LLM%20Quantization&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLM Quantization on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f&title=LLM%20Quantization">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLM Quantization on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLM Quantization on whatsapp"
            href="https://api.whatsapp.com/send?text=LLM%20Quantization%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLM Quantization on telegram"
            href="https://telegram.me/share/url?text=LLM%20Quantization&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share LLM Quantization on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=LLM%20Quantization&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fquant%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>@ 2024 Zhiyang Shen</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
