+++
title = 'Research Idea'
date = 2025-08-16T18:21:52+08:00
draft = false
math = true
tags = ['note']
categories = ['note', 'visualization', 'math']
summary = "Record some research ideas of my interest."
+++

This post records some research ideas of my interest.

> 靡不有初，鲜克有终。

## composite.js

The rendering tool used in our composite visualization project
can be converted into a useful javascript library (although we have
to refactor the code).
The purpose of this tool is to make it easier for users to design
and create composite visualizations.

Reference:
- PiCCL: Data-Driven Composition of Bespoke Pictorial Charts
- Manipulable Semantic Components: a Computational Representation of Data
  Visualization Scenes

A basic example:

```javascript
import * from composite;

const chart1 = createChart('bar', data1, config1);
const chart2 = createChart('line', data2, config2);
const composite = compose(chart1, chart2, 'stack', 'vertical');
composite.toSVG('result.svg');
```

Users can either use the built-in chart rendering function in our tool,
or customize their own rendering functions for new chart types or variants.
This makes our method extensible.

## Diffusing Game of Life

Inspired by [Physics of Language Models](https://physics.allen-zhu.com/home),
I want to investigate the physics of diffusion models.
The general method of PhysicLM is to construct controllable environments 
to train language models and make observations, instead of directing playing
with pretrained large language models.

For example, to examine the ability of language models to learn grammar,
Allen Zhu designed a group of CFGs, and trained a language model from scratch.
After that, by observing the hidden layers and activations of the model,
he concluded with some interesting takeaways.

A similar approach is to transfer this research style into 
the understanding of diffusion models. Then, what environments can I design
to construct controlled experiments? The only thing we need to do is
to generate enough training data ("enough" is not enough, 
we actually want "infinite"!) to train a diffusion model to learn the rules
(*i.e.*, the physic of this designed world).

Therefore, the first thing that comes to my mind is Conway's Game of Life.
It has specific rules for state transfer, and has infinite states. Besides,
a key advantage of this environment is that,
a minor change in the input state may lead to a 
significant change in output states.
We can test if a diffusion model can actually learn the rules
of this game. My belief is that, a diffusion (or flow matching) model
actually learns the "transfer" from one distribution to another distribution.
This makes it possible for these models to learn the specific rules.

## Infographic Generation

It's hard for diffusion models to generate charts, mainly because of
the lack of fidelity, *i.e.*, the generated charts cannot accurately encode
the original values in the data. However, diffusion models also have their
own advantages: the generated charts are often appealing in aesthetics,
compared with the charts generated by machine code (*e.g.* D3.js).

Therefore, it's interesting to think that, how to ensure data fidelity
in diffusion models? I think it not reasonable to prompt the model
with only input data (which is an end-to-end solution), because the model
may fail to understand the data themselves. Nevertheless, we can address
this issue by another approach.

Previous work, [Let the Chart Spark](https://arxiv.org/abs/2304.14630),
already tried to handle this problem, but in a non-automatic manner.
That is, the generated chart elements (*i.e.*, bars, points) cannot be
directly positioned into the image, but require human adjustment & authoring.

What if we move a step further? Can we automatically generate charts?
To do this, we need to precisely control the bounding box of the chart elements,
which is a classical task in diffusion models. Several works have been proposed,
such as [ControlNet](https://arxiv.org/abs/2302.05543) and [T2I-Adapter](https://arxiv.org/abs/2302.08453).
Given conditional controls (*e.g.*, sketch, edges, segmentation), the models
can perfectly follow the control signals when generating images.

Perhaps somewhere in the world there are a lot of people working on this
problem? I think it's promising in the future, both for the visualization
community and for the AI community.

## Understanding Flow Matching Models

This is another idea about explainable machine learning.

Flow matching models, in essence, learn the "transfer" from one distribution
to another distribution using ODE. It's natural to wonder that, how to visualize
the "flow" between two distributions? Can we dig deeper into the models by
analyzing the distributions and their relationships?

To do this, we first need to reduce the dimensions to 2D. Traditional dimension
reduction methods such as tSNE and UMAP may not be the best for this specific
task. Can we develop new methods that are most suitable for these models?

## Thinking Compression

Nowadays, LLMs use chain-of-thought mechanism to "reason" better.
Many LLM applications, such as GPT-5 and Gemini-2.5-Pro, show the "explicit"
thinking process to the users. However, is thinking always helpful? Are there
any useless information in the thinking process, which may harm the model
to answer correctly?

There are two things coming to my mind.
- First, I want to test the assumptions above. For a locally-deployed model,
I can manually edit the KV-cache in thinking process after the `</think>` token
is generated. Specifically, I want to remove some thinking tokens.
In this way, the tokens after `</think>` (which are the answers) will not see these
"harmful" tokens. What will the result become? Can the model still answer
correctly? Or is there any improvement in accuracy?
- Second, if the assumptions are proved to be true, it means that, **thinking
doesn't need to perform on token level**. Instead, the thinking tokens can be
"compressed", which is done in a "latent" space using another model.
Strategies such as VAE may be utilized to do this.

It's quite interesting, because it can both improve the accuracy of the model
and reduce the time requried for thinking.